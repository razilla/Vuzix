package com.example.ar

import android.Manifest
import android.content.Intent
import android.content.pm.PackageManager
import android.graphics.Bitmap
import android.os.Bundle
import android.provider.MediaStore
import androidx.activity.ComponentActivity
import androidx.activity.compose.setContent
import androidx.activity.result.ActivityResultLauncher
import androidx.activity.result.contract.ActivityResultContracts
import androidx.compose.foundation.Image
import androidx.compose.foundation.layout.Column
import androidx.compose.foundation.layout.fillMaxSize
import androidx.compose.foundation.layout.padding
import androidx.compose.material3.MaterialTheme
import androidx.compose.material3.Surface
import androidx.compose.material3.Text
import androidx.compose.runtime.Composable
import androidx.compose.runtime.mutableStateOf
import androidx.compose.ui.Modifier
import androidx.compose.ui.graphics.asImageBitmap
import androidx.compose.ui.unit.dp
import androidx.core.app.ActivityCompat
import androidx.core.content.ContextCompat
import com.example.ar.ui.theme.ARTheme
import com.google.mlkit.vision.common.InputImage
import com.google.mlkit.vision.text.TextRecognition
import com.google.mlkit.vision.text.latin.TextRecognizerOptions
import retrofit2.Retrofit
import retrofit2.converter.gson.GsonConverterFactory
import retrofit2.Call
import retrofit2.Callback
import retrofit2.Response
import android.util.Log
import com.example.ar.OpenAIApiService
import com.example.ar.RequestBody
import com.example.ar.ResponseBody


class MainActivity : ComponentActivity() {

    private lateinit var cameraLauncher: ActivityResultLauncher<Intent>
    private var imageBitmap: Bitmap? = null
    private var extractedTextState = mutableStateOf("")
    private var imageBitmapState = mutableStateOf<Bitmap?>(null)
    private var chatGPTResponseState = mutableStateOf("")
    private val retrofit: Retrofit by lazy {
        Retrofit.Builder()
            .baseUrl("https://api.openai.com/")
            .addConverterFactory(GsonConverterFactory.create())
            .build()
    }

    private val openAIApiService: OpenAIApiService by lazy {
        retrofit.create(OpenAIApiService::class.java)
    }

    override fun onCreate(savedInstanceState: Bundle?) {
        super.onCreate(savedInstanceState)

        cameraLauncher = registerForActivityResult(ActivityResultContracts.StartActivityForResult()) { result ->
            if (result.resultCode == RESULT_OK) {
                val data: Intent? = result.data
                imageBitmap = data?.extras?.get("data") as Bitmap?
                imageBitmap?.let {
                    processImageWithOCR(it)
                }
            }
        }

        checkCameraPermission()

        setContent {
            ARTheme {
                Surface(
                    modifier = Modifier.fillMaxSize(),
                    color = MaterialTheme.colorScheme.background
                ) {
                    ImageAndTextDisplay(imageBitmapState.value, extractedTextState.value, chatGPTResponseState.value)
                }
            }
        }

    }

    private fun dispatchTakePictureIntent() {
        val takePictureIntent = Intent(MediaStore.ACTION_IMAGE_CAPTURE)
        try {
            cameraLauncher.launch(takePictureIntent)
        } catch (e: Exception) {
            // Handle the exception
        }
    }

    private fun checkCameraPermission() {
        if (ContextCompat.checkSelfPermission(this, Manifest.permission.CAMERA) != PackageManager.PERMISSION_GRANTED) {
            requestCameraPermission()
        } else {
            dispatchTakePictureIntent()
        }
    }

    private fun requestCameraPermission() {
        ActivityCompat.requestPermissions(this, arrayOf(Manifest.permission.CAMERA), REQUEST_CAMERA_PERMISSION)
    }

    override fun onRequestPermissionsResult(requestCode: Int, permissions: Array<String>, grantResults: IntArray) {
        super.onRequestPermissionsResult(requestCode, permissions, grantResults)
        when (requestCode) {
            REQUEST_CAMERA_PERMISSION -> {
                if ((grantResults.isNotEmpty() && grantResults[0] == PackageManager.PERMISSION_GRANTED)) {
                    dispatchTakePictureIntent()
                } else {
                    // Permission denied, handle appropriately
                }
            }
        }
    }

    private fun processImageWithOCR(bitmap: Bitmap) {
        val image = InputImage.fromBitmap(bitmap, 0)
        val recognizer = TextRecognition.getClient(TextRecognizerOptions.DEFAULT_OPTIONS)

        recognizer.process(image)
            .addOnSuccessListener { visionText ->
                Log.d("MainActivity", "OCR Text: ${visionText.text}")
                extractedTextState.value = visionText.text
                sendTextToOpenAI(visionText.text)
            }
            .addOnFailureListener { e ->
                Log.d("MainActivity", "OCR Error: ${e.message}")
            }
    }

    // Send Text to OpenAI and Handle Response
    private fun sendTextToOpenAI(text: String) {
        val requestBody = RequestBody(text, 50)  // Adjust max_tokens as needed
        // Retrofit test
        RetrofitService.service.createCompletion(requestBody).enqueue(object : Callback<ResponseBody> {
        //Originial
        //openAIApiService.createCompletion(requestBody).enqueue(object : Callback<ResponseBody> {
            override fun onResponse(call: Call<ResponseBody>, response: Response<ResponseBody>) {
                if (response.isSuccessful) {

                    response.body()?.let {
                        Log.d("MainActivity", "OpenAI Response: ${it.choices.first().text}")
                        chatGPTResponseState.value = "OpenAI Response: ${it.choices.first().text}"
                    }
                } else {
                    Log.d("MainActivity", "API Error: Response not successful, Code: ${response.code()}")
                }
            }

            override fun onFailure(call: Call<ResponseBody>, t: Throwable) {
                Log.d("MainActivity", "API Failure: ${t.message}")
            }
        })
    }



    companion object {
        const val REQUEST_CAMERA_PERMISSION = 1
    }
}

@Composable
fun ImageAndTextDisplay(imageBitmap: Bitmap?, extractedText: String, chatGPTResponse: String) {
    Column(modifier = Modifier.padding(16.dp)) {
        imageBitmap?.let {
            Image(bitmap = it.asImageBitmap(), contentDescription = "Captured Image")
        }
        Text(text = "Extracted Text: $extractedText")
        Text(text = chatGPTResponse)
    }
}
